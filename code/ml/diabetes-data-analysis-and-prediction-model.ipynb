{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4289678,"sourceType":"datasetVersion","datasetId":2527538}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Diabetes is a chronic disease that affects millions of people worldwide. Understanding the factors that contribute to diabetes can help in early diagnosis and management. In this notebook, we will explore a dataset containing various health metrics of individuals and their diabetes status. Our goal is to uncover insights and potentially build a predictive model for diabetes diagnosis.\n\nIf you find this notebook useful, please consider upvoting it.","metadata":{}},{"cell_type":"code","source":"# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:12:24.659933Z","iopub.execute_input":"2024-08-30T13:12:24.660357Z","iopub.status.idle":"2024-08-30T13:12:27.076978Z","shell.execute_reply.started":"2024-08-30T13:12:24.660317Z","shell.execute_reply":"2024-08-30T13:12:27.075823Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\nfile_path = '/kaggle/input/diabetes-dataset/diabetes.csv'\ndf = pd.read_csv(file_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:12:27.079148Z","iopub.execute_input":"2024-08-30T13:12:27.079884Z","iopub.status.idle":"2024-08-30T13:12:27.129953Z","shell.execute_reply.started":"2024-08-30T13:12:27.079811Z","shell.execute_reply":"2024-08-30T13:12:27.128655Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Exploration\nLet's start by exploring the dataset to understand the distribution of the features and the target variable.","metadata":{}},{"cell_type":"code","source":"# Basic statistics of the dataset\ndf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for Missing Values\nIt's important to check if there are any missing values in the dataset.","metadata":{}},{"cell_type":"code","source":"# Check for missing values\ndf.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Heatmap\nLet's visualize the correlation between different features using a heatmap.","metadata":{}},{"cell_type":"code","source":"# Correlation heatmap\nnumeric_df = df.select_dtypes(include=[np.number])\nplt.figure(figsize=(12, 8))\nsns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization\nLet's create some visualizations to better understand the distribution of the features.","metadata":{}},{"cell_type":"code","source":"# Distribution of Age\nplt.figure(figsize=(10, 6))\nsns.histplot(df['Age'], kde=True, bins=30)\nplt.title('Age Distribution')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of BMI\nplt.figure(figsize=(10, 6))\nsns.histplot(df['BMI'], kde=True, bins=30)\nplt.title('BMI Distribution')\nplt.xlabel('BMI')\nplt.ylabel('Frequency')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building a Predictive Model\nGiven the dataset, it would be interesting to build a predictive model to diagnose diabetes. We will use Logistic Regression for this task.","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:12:50.115975Z","iopub.execute_input":"2024-08-30T13:12:50.116970Z","iopub.status.idle":"2024-08-30T13:12:50.132691Z","shell.execute_reply.started":"2024-08-30T13:12:50.116923Z","shell.execute_reply":"2024-08-30T13:12:50.131607Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(accuracy_score(y_train, knn.predict(X_train)))\nknn_acc = accuracy_score(y_test, knn.predict(X_test))\nprint(accuracy_score(y_test, knn.predict(X_test)))\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:13:53.025659Z","iopub.execute_input":"2024-08-30T13:13:53.026124Z","iopub.status.idle":"2024-08-30T13:13:53.192028Z","shell.execute_reply.started":"2024-08-30T13:13:53.026069Z","shell.execute_reply":"2024-08-30T13:13:53.190735Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"0.7980456026058632\n0.6623376623376623\n[[70 29]\n [23 32]]\n              precision    recall  f1-score   support\n\n           0       0.75      0.71      0.73        99\n           1       0.52      0.58      0.55        55\n\n    accuracy                           0.66       154\n   macro avg       0.64      0.64      0.64       154\nweighted avg       0.67      0.66      0.67       154\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:12:50.338676Z","iopub.execute_input":"2024-08-30T13:12:50.339144Z","iopub.status.idle":"2024-08-30T13:12:50.389681Z","shell.execute_reply.started":"2024-08-30T13:12:50.339100Z","shell.execute_reply":"2024-08-30T13:12:50.388306Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC(C=0.5, gamma = 0.1, probability=True)\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\nprint(accuracy_score(y_train, svc.predict(X_train)))\nsvc_acc = accuracy_score(y_test, svc.predict(X_test))\nprint(accuracy_score(y_test, svc.predict(X_test)))\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:14:55.157914Z","iopub.execute_input":"2024-08-30T13:14:55.158375Z","iopub.status.idle":"2024-08-30T13:14:55.370041Z","shell.execute_reply.started":"2024-08-30T13:14:55.158332Z","shell.execute_reply":"2024-08-30T13:14:55.368771Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0.6530944625407166\n0.6428571428571429\n[[99  0]\n [55  0]]\n              precision    recall  f1-score   support\n\n           0       0.64      1.00      0.78        99\n           1       0.00      0.00      0.00        55\n\n    accuracy                           0.64       154\n   macro avg       0.32      0.50      0.39       154\nweighted avg       0.41      0.64      0.50       154\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from xgboost import XGBClassifier \nxgb = XGBClassifier(objective = 'binary:logistic', learning_rate = 0.01, max_depth = 10, n_estimators = 180)\n\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\nprint(accuracy_score(y_train, xgb.predict(X_train)))\nxgb_acc = accuracy_score(y_test, xgb.predict(X_test))\nprint(accuracy_score(y_test, xgb.predict(X_test)))\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:15:33.565971Z","iopub.execute_input":"2024-08-30T13:15:33.566454Z","iopub.status.idle":"2024-08-30T13:15:34.073834Z","shell.execute_reply.started":"2024-08-30T13:15:33.566411Z","shell.execute_reply":"2024-08-30T13:15:34.072927Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"0.9788273615635179\n0.7207792207792207\n[[78 21]\n [22 33]]\n              precision    recall  f1-score   support\n\n           0       0.78      0.79      0.78        99\n           1       0.61      0.60      0.61        55\n\n    accuracy                           0.72       154\n   macro avg       0.70      0.69      0.69       154\nweighted avg       0.72      0.72      0.72       154\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nmodel = xgb\npickle.dump(model, open(\"diabetes_xgb.pkl\",'wb'))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:16:43.175490Z","iopub.execute_input":"2024-08-30T13:16:43.175965Z","iopub.status.idle":"2024-08-30T13:16:43.194604Z","shell.execute_reply.started":"2024-08-30T13:16:43.175920Z","shell.execute_reply":"2024-08-30T13:16:43.193374Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:12:55.721880Z","iopub.execute_input":"2024-08-30T13:12:55.722321Z","iopub.status.idle":"2024-08-30T13:12:55.734017Z","shell.execute_reply.started":"2024-08-30T13:12:55.722279Z","shell.execute_reply":"2024-08-30T13:12:55.732876Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0.7467532467532467"},"metadata":{}}]},{"cell_type":"code","source":"# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:13:00.937469Z","iopub.execute_input":"2024-08-30T13:13:00.937918Z","iopub.status.idle":"2024-08-30T13:13:00.954800Z","shell.execute_reply.started":"2024-08-30T13:13:00.937876Z","shell.execute_reply":"2024-08-30T13:13:00.953675Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.81      0.79      0.80        99\n           1       0.64      0.67      0.65        55\n\n    accuracy                           0.75       154\n   macro avg       0.73      0.73      0.73       154\nweighted avg       0.75      0.75      0.75       154\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Conclusion and Future Work\nIn this notebook, we explored the diabetes dataset, visualized the data, and built a predictive model using Logistic Regression. The model's accuracy and other metrics provide a baseline for further improvements.\n\nFuture work could include:\n- Trying different machine learning algorithms (e.g., Random Forest, SVM)\n- Hyperparameter tuning to improve model performance\n- Feature engineering to create new features from existing ones\n\nWhat do you think would be useful to explore next?","metadata":{}},{"cell_type":"markdown","source":"## Credits\nThis notebook was created with the help of [Devra AI data science assistant](https://devra.ai/ref/kaggle)","metadata":{}}]}